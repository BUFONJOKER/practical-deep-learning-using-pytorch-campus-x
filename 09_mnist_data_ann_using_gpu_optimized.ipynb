{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "40f38418",
   "metadata": {},
   "source": [
    "# Fashion Mnist Dataset Artificial Neural Network Optimized with Dropout, Batch Normalization and L2 Regularization using Pytorch"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2055ae99",
   "metadata": {},
   "source": [
    "## Import Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ede44ea1",
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mFailed to start the Kernel 'Python 3 (ipykernel)'. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details. Unable to get resolved server information for google.colab:colab:6301c3e0-8387-4ea6-80be-75108cf917b2"
     ]
    }
   ],
   "source": [
    "# library to see model summary\n",
    "!pip install torchinfo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "1f3dc563",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import kagglehub\n",
    "import random\n",
    "import matplotlib.pyplot as plt\n",
    "from torchinfo import summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "1b2d3743",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.accelerator.current_accelerator().type if torch.accelerator.is_available() else \"cpu\"\n",
    "print(f\"Using {device} device\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b7efe6ea",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "7182ec9f",
   "metadata": {},
   "source": [
    "## Loading the Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "7c5f62f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_path = kagglehub.dataset_download('zalando-research/fashionmnist')\n",
    "csv_file_path = f'{dataset_path}/fashion-mnist_train.csv'\n",
    "df_train = pd.read_csv(csv_file_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c7c79416",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a54037b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "3221469d",
   "metadata": {},
   "outputs": [],
   "source": [
    "csv_file_path = f'{dataset_path}/fashion-mnist_test.csv'\n",
    "df_test = pd.read_csv(csv_file_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "36688e10",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_test.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "d8ecdd05",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_test.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a65b74cf",
   "metadata": {},
   "source": [
    "## Viewing the Random Image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "a8e85e12",
   "metadata": {},
   "outputs": [],
   "source": [
    "# train image\n",
    "random_index = random.randint(0,len(df_train))\n",
    "image = df_train.iloc[random_index,1:].values.reshape(28,28)\n",
    "plt.imshow(image)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "666e7d1d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# test image\n",
    "random_index = random.randint(0,len(df_test))\n",
    "image = df_test.iloc[random_index,1:].values.reshape(28,28)\n",
    "plt.imshow(image)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "15bf4ce4",
   "metadata": {},
   "source": [
    "## Splitting the Dataset into Training and Testing Sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "76113266",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = df_train.iloc[:, 1:].values\n",
    "y_train = df_train.iloc[:, 0].values\n",
    "X_test = df_test.iloc[:, 1:].values\n",
    "y_test = df_test.iloc[:, 0].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "6241ed78",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = X_train / 255.0\n",
    "X_test = X_test / 255.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b0ed727d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "2ba528f7",
   "metadata": {},
   "source": [
    "## Crating Custom Dataset Class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "04bc4dc8",
   "metadata": {},
   "outputs": [],
   "source": [
    "class CustomDataset(Dataset):\n",
    "\n",
    "    def __init__(self, features, labels):\n",
    "        self.features = torch.tensor(features, dtype=torch.float32)\n",
    "        self.labels = torch.tensor(labels, dtype=torch.long)\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.features)\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        return self.features[index], self.labels[index]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "4f7faaf0",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_datataset = CustomDataset(features=X_train, labels=y_train)\n",
    "test_datataset = CustomDataset(features=X_test, labels=y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "813bf386",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataloader = DataLoader(train_datataset, batch_size=32, shuffle=True, pin_memory=True)\n",
    "test_dataloader = DataLoader(test_datataset, batch_size=32, shuffle=False, pin_memory=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f11e14a5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "c52dca29",
   "metadata": {},
   "source": [
    "## Model Building, Training and Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "c0f457a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# crating model Class\n",
    "class Model(nn.Module):\n",
    "\n",
    "    def __init__(self, num_features):\n",
    "        super().__init__()\n",
    "\n",
    "        self.model = nn.Sequential(\n",
    "            # first layer\n",
    "            nn.Linear(num_features, 128),\n",
    "            nn.BatchNorm1d(128),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(p=0.2),\n",
    "            # second layer\n",
    "            nn.Linear(128,64),\n",
    "            nn.BatchNorm1d(64),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(p=0.2),\n",
    "            # output layer\n",
    "            nn.Linear(64,10)\n",
    "        )\n",
    "\n",
    "    def forward(self, features):\n",
    "        return self.model(features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "cd47249c",
   "metadata": {},
   "outputs": [],
   "source": [
    "learning_rate=0.1\n",
    "epochs=100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "8cdaf61a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# creatind model object of Mode Class we creates above\n",
    "model = Model(num_features=X_train.shape[1]).to(device)\n",
    "\n",
    "# loss function\n",
    "loss_function = nn.CrossEntropyLoss()\n",
    "\n",
    "# optimizer with weight decay for L2 regularization\n",
    "optimizer = optim.SGD(params=model.parameters(), lr=learning_rate, weight_decay=1e-4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "ca0a6c1c",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(summary(model))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "ea6ab0db",
   "metadata": {},
   "outputs": [],
   "source": [
    "# training loop\n",
    "for epoch in range(epochs):\n",
    "\n",
    "    total_epoch_loss=0\n",
    "    for batch_features, batch_labels in train_dataloader:\n",
    "\n",
    "        # move data to gpu\n",
    "        batch_features, batch_labels = batch_features.to(device), batch_labels.to(device)\n",
    "\n",
    "        # forward pass\n",
    "        y_pred = model(batch_features)\n",
    "        \n",
    "        # loss calculate\n",
    "        loss = loss_function(y_pred, batch_labels)\n",
    "        \n",
    "        # clear gradients\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        # backward pass\n",
    "        loss.backward()\n",
    "\n",
    "        # update gradients\n",
    "        optimizer.step()\n",
    "\n",
    "        # calculate loss for each batchs\n",
    "        total_epoch_loss += loss.item()\n",
    "\n",
    "    # average loss of batches\n",
    "    avg_loss = total_epoch_loss/len(train_dataloader)\n",
    "\n",
    "    print(f\"Epoch: {epoch + 1}, Loss:{avg_loss}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "164ff2ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "# setting model to evaluation mode\n",
    "model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "25225eb5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# evaluation code\n",
    "total = 0 \n",
    "correct = 0\n",
    "with torch.no_grad():\n",
    "\n",
    "    for batch_features, batch_labels in test_dataloader:\n",
    "\n",
    "        # move data to gpu\n",
    "        batch_features, batch_labels = batch_features.to(device), batch_labels.to(device)\n",
    "\n",
    "        y_pred = model(batch_features)\n",
    "\n",
    "        _, predicted = torch.max(y_pred, 1)\n",
    "\n",
    "        total += batch_labels.shape[0]\n",
    "\n",
    "        correct += (predicted==batch_labels).sum().item()\n",
    "\n",
    "print(f\"Accuracy on Test Data: {(correct/total)*100}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "99702048",
   "metadata": {},
   "outputs": [],
   "source": [
    "# evaluation code\n",
    "total = 0 \n",
    "correct = 0\n",
    "with torch.no_grad():\n",
    "\n",
    "    for batch_features, batch_labels in train_dataloader:\n",
    "\n",
    "        # move data to gpu\n",
    "        batch_features, batch_labels = batch_features.to(device), batch_labels.to(device)\n",
    "\n",
    "        y_pred = model(batch_features)\n",
    "\n",
    "        _, predicted = torch.max(y_pred, 1)\n",
    "\n",
    "        total += batch_labels.shape[0]\n",
    "\n",
    "        correct += (predicted==batch_labels).sum().item()\n",
    "\n",
    "print(f\"Accuracy on Train Data: {(correct/total)*100}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b3a1ba3",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
